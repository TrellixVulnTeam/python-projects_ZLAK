{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Tapology scraper I made to gather all of the mma gyms in the US\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#List of all the states to append to the URL\n",
    "states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "          \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "          \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "          \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "          \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "\n",
    "state_dfs = []\n",
    "\n",
    "#Go through all of the Tapology.com State list pages and take the data\n",
    "for state in states:\n",
    "    r=requests.get(\"http://www.tapology.com/gyms/state/\"+state, verify=False)\n",
    "    c=r.content\n",
    "\n",
    "    soup=BeautifulSoup(c, \"html.parser\")\n",
    "    all_gyms=soup.find_all(\"tr\")\n",
    "\n",
    "    l=[]\n",
    "    counter = 0\n",
    "    \n",
    "    for gym in all_gyms:\n",
    "        d={}\n",
    "        rows = gym.find_all('td', {\"class\": \"noBorder\"})\n",
    "        counter = 0\n",
    "    \n",
    "        for row in rows:\n",
    "            if counter == 0:\n",
    "                d[\"Name\"] = row.text\n",
    "                d[\"Link\"] = row.find('a').get('href')\n",
    "                counter += 1\n",
    "            elif counter == 1:\n",
    "                d[\"Location\"] = row.text\n",
    "                counter += 1\n",
    "            elif counter == 2:\n",
    "                d[\"Phone\"] = row.text\n",
    "                counter +=1\n",
    "            else:\n",
    "                try:\n",
    "                    site = row.find('a')\n",
    "                    d[\"Website\"] = site.get('href')\n",
    "                    counter = 0\n",
    "                except:\n",
    "                    d[\"Website\"] = \"\"\n",
    "                    counter = 0\n",
    "        l.append(d)\n",
    "\n",
    "    #List comprehension to remove all blank objects within our list\n",
    "    l[:] = [x for x in l if x != {}]\n",
    "\n",
    "    #Put it into a DataFrame for usage in a Jupyter Notebook\n",
    "    df = pd.DataFrame(l)\n",
    "    state_dfs.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state_dfs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a6202c8eac40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnew_gyms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mgym\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstate_dfs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'state_dfs' is not defined"
     ]
    }
   ],
   "source": [
    "#Need to figure out why the 'for social' loop is not matching the strings.\n",
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "#Use the list of links scraped from the first pull to go into the detail pages for each gym and pull relevant information.\n",
    "new_gyms = []\n",
    "\n",
    "for gym in state_dfs:\n",
    "    n=[]\n",
    "    count = 0\n",
    "    for index, row in gym.iterrows():\n",
    "        new_r=requests.get(\"http://www.tapology.com\"+row['Link'], verify=False)\n",
    "        new_c=new_r.content\n",
    "\n",
    "        new_soup=BeautifulSoup(new_c, \"html.parser\")\n",
    "        new_all_gyms=new_soup.find_all(\"div\", {\"class\": \"details\"})\n",
    "\n",
    "        new_gyms.append(new_all_gyms)\n",
    "        \n",
    "        rows2 = new_gyms[index][0].find_all('a')\n",
    "        \n",
    "        socials = ['Facebook', 'Yelp', 'Twitter', 'Official Site']\n",
    "        f={}\n",
    "        gymname = new_soup.find_all(\"div\", {\"class\": \"pageHeading\"})\n",
    "        f['Gym'] = gymname[0].find('h1').text\n",
    "        \n",
    "        try:\n",
    "            f['Logo'] = new_all_gyms[0].img['src']\n",
    "        except:\n",
    "            f['Logo'] = ''\n",
    "        \n",
    "        \n",
    "        count += 1\n",
    "        print(count)\n",
    "        for row2 in rows2:\n",
    "            if row2.text in socials:\n",
    "                f[row2.text] = row2.get('href')\n",
    "        \n",
    "        n.append(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Facebook': 'http://www.facebook.com/AuburnMixedMartialArts',\n",
       " 'Gym': 'Auburn Mixed Martial Arts',\n",
       " 'Logo': 'https://images.tapology.com/gyms/logos/341/profile/341-auburn-mma.jpg?1408756602',\n",
       " 'Official Site': 'http://www.auburnmma.com/'}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n[2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "count = 0\n",
    "for df in state_dfs:\n",
    "    df.to_excel(writer,sheet_name=states[count], index=False)\n",
    "    writer.save()\n",
    "    count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
